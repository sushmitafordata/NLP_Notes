{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Gensim and spaCy are both popular Python libraries used for natural language processing (NLP) tasks, but they serve different purposes and have different focuses.\n",
        "\n",
        "1. Functionality:\n",
        "   - Gensim: Gensim is primarily focused on topic modeling, document similarity, and unsupervised learning for large text corpora. It provides efficient implementations of algorithms like Latent Semantic Analysis (LSA), Latent Dirichlet Allocation (LDA), and Word2Vec.\n",
        "   \n",
        "   - spaCy: spaCy, on the other hand, is a more comprehensive NLP library that offers a wide range of functionalities, including tokenization, named entity recognition (NER), part-of-speech (POS) tagging, dependency parsing, and more. It is designed for building practical, production-ready NLP pipelines.\n",
        "\n",
        "2. Design Philosophy:\n",
        "   - Gensim: Gensim focuses on providing simple and efficient implementations of algorithms for working with large volumes of text data. It emphasizes scalability, memory efficiency, and ease of use. Gensim is particularly useful for tasks like document similarity, text summarization, and topic modeling.\n",
        "\n",
        "   - spaCy: spaCy is designed to be a full-featured NLP library that combines efficiency with usability. It aims to provide fast and accurate results while being user-friendly. spaCy includes pre-trained models for many languages and offers convenient features for common NLP tasks, such as named entity recognition, POS tagging, and dependency parsing.\n",
        "\n",
        "3. Pre-trained Models:\n",
        "   - Gensim: Gensim does not provide pre-trained models out-of-the-box. Instead, it focuses on providing algorithms and tools for training your own models on custom text corpora.\n",
        "\n",
        "   - spaCy: spaCy comes with a range of pre-trained models for various NLP tasks, including tokenization, POS tagging, NER, and dependency parsing. These models are trained on large, diverse datasets and can be easily loaded and used for various NLP tasks.\n",
        "\n",
        "In summary, Gensim is more specialized for topic modeling and unsupervised learning, while spaCy offers a broader set of NLP functionalities and pre-trained models for tasks like tokenization, NER, and dependency parsing. The choice between Gensim and spaCy depends on the specific requirements of your NLP project."
      ],
      "metadata": {
        "id": "FsqpbymffZC3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Word Vectors Overview Using Gensim Library"
      ],
      "metadata": {
        "id": "_7abzuUClM4h"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uDTTdxwIb72T",
        "outputId": "025a34da-da6a-4eee-eb33-2c1a26de20ce"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[==================================================] 100.0% 1662.8/1662.8MB downloaded\n"
          ]
        }
      ],
      "source": [
        "import gensim.downloader as api\n",
        "\n",
        "# We are loading an model which is trained on google news\n",
        "wv = api.load('word2vec-google-news-300')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "All gensim models are listed on this page: https://github.com/RaRe-Technologies/gensim-data"
      ],
      "metadata": {
        "id": "QHlOcsJwgHRy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Showing the context similarity\n",
        "wv.similarity(w1=\"great\",w2=\"good\")"
      ],
      "metadata": {
        "id": "Tzh2Ah_2dR_t",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d9b57cf1-49f4-49fd-bd64-c9a4c865f55f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.729151"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "wv.similarity(w1=\"profit\",w2=\"loss\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DnmdiA7WgRt2",
        "outputId": "2500b9f4-6b00-49af-e019-2dae095e1f2c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.34199455"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#words which appear in the similar word context\n",
        "\n",
        "wv.most_similar(\"good\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QsarVfoXgdv1",
        "outputId": "ecc8f5af-3e8b-4878-c16c-6ad0cee34c87"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('great', 0.7291510105133057),\n",
              " ('bad', 0.7190051078796387),\n",
              " ('terrific', 0.6889115571975708),\n",
              " ('decent', 0.6837348341941833),\n",
              " ('nice', 0.6836092472076416),\n",
              " ('excellent', 0.644292950630188),\n",
              " ('fantastic', 0.6407778263092041),\n",
              " ('better', 0.6120728850364685),\n",
              " ('solid', 0.5806034803390503),\n",
              " ('lousy', 0.576420247554779)]"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "wv.most_similar(\"cat\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "salxESk7gkLv",
        "outputId": "5a7d029b-e4f1-4e1d-9620-7c22b28cf2a1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('cats', 0.8099379539489746),\n",
              " ('dog', 0.760945737361908),\n",
              " ('kitten', 0.7464985251426697),\n",
              " ('feline', 0.7326234579086304),\n",
              " ('beagle', 0.7150582671165466),\n",
              " ('puppy', 0.7075453400611877),\n",
              " ('pup', 0.6934291124343872),\n",
              " ('pet', 0.6891531348228455),\n",
              " ('felines', 0.6755931973457336),\n",
              " ('chihuahua', 0.6709762215614319)]"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- King - woman + Man = Queen\n",
        "- France - Paris +Berlin = Germany"
      ],
      "metadata": {
        "id": "okBp6qA_kJYy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "wv.most_similar(positive=[\"france\",\"berlin\"],negative=[\"paris\"])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ksEQxVBkjT1U",
        "outputId": "ae2d6256-937e-4047-8d10-5506beed6c6b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('germany', 0.5094343423843384),\n",
              " ('european', 0.48650455474853516),\n",
              " ('german', 0.4714890420436859),\n",
              " ('austria', 0.46964022517204285),\n",
              " ('swedish', 0.4645182490348816),\n",
              " ('Wissenschaft', 0.4532880485057831),\n",
              " ('denmark', 0.4477355182170868),\n",
              " ('MÃ¼nchen', 0.4438532590866089),\n",
              " ('europe', 0.4420619308948517),\n",
              " ('belgium', 0.43769752979278564)]"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "wv.most_similar(positive=[\"king\",\"woman\"],negative=[\"man\"])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0pcUcAlpkgVk",
        "outputId": "739d56e1-cefd-43f8-bace-63b8ce4b932c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('queen', 0.7118193507194519),\n",
              " ('monarch', 0.6189674139022827),\n",
              " ('princess', 0.5902431011199951),\n",
              " ('crown_prince', 0.5499460697174072),\n",
              " ('prince', 0.5377321839332581),\n",
              " ('kings', 0.5236844420433044),\n",
              " ('Queen_Consort', 0.5235945582389832),\n",
              " ('queens', 0.5181134343147278),\n",
              " ('sultan', 0.5098593831062317),\n",
              " ('monarchy', 0.5087411999702454)]"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "wv.doesnt_match([\"facebook\",\"cat\",\"lion\",\"microsoft\"])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "QjJz9WnhksU3",
        "outputId": "e6b38c26-3e1f-4021-bec7-2def77fc0460"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'facebook'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Gensim: Glove\n",
        "Stanford's page on GloVe: https://nlp.stanford.edu/projects/glove/"
      ],
      "metadata": {
        "id": "ITfppDLSlOuY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "glv = api.load(\"glove-twitter-25\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mtGAr1fnlCHd",
        "outputId": "d8f5cdf9-d091-4c8f-8366-f42678c706e7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[==================================================] 100.0% 104.8/104.8MB downloaded\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "glv.most_similar(\"good\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sLmmBjIDlUOi",
        "outputId": "7e668843-5e6b-4377-8718-ca70a156e96b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('too', 0.9648017287254333),\n",
              " ('day', 0.9533665180206299),\n",
              " ('well', 0.9503170847892761),\n",
              " ('nice', 0.9438973665237427),\n",
              " ('better', 0.9425962567329407),\n",
              " ('fun', 0.9418926239013672),\n",
              " ('much', 0.9413353800773621),\n",
              " ('this', 0.9387555122375488),\n",
              " ('hope', 0.9383506774902344),\n",
              " ('great', 0.9378516674041748)]"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- The similarities of words compared using genism using word2vec news data and glove technique twitter data the context is different."
      ],
      "metadata": {
        "id": "2JUvbof-lu6i"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "r2627w-UlYWZ"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}