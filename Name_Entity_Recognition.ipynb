{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "- Name Entity Recognition (NER) is a natural language processing (NLP) technique used to identify and classify named entities in text into predefined categories such as person names, organizations, locations, dates, and more.\n",
        "\n",
        "- The objective of NER is to extract meaningful information from unstructured text and understand the context of the text by recognizing and classifying specific named entities."
      ],
      "metadata": {
        "id": "miYr0Z-SiGWh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- The output of an NER system is typically a set of recognized entities along with their corresponding categories\n",
        "\n",
        "-  For example, given the sentence \"Apple Inc. is planning to open a new store in New York next month,\" an NER system would identify \"Apple Inc.\" as an organization, \"New York\" as a location, and recognize the temporal expression \"next month\" as a date."
      ],
      "metadata": {
        "id": "C6tMeZSSiQt9"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PJ0oU-fFhQwq"
      },
      "outputs": [],
      "source": [
        "import spacy\n",
        "nlp=spacy.load(\"en_core_web_sm\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "nlp.pipe_names"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PTx6NVq-mqmD",
        "outputId": "59c80a66-44ee-48da-d879-73f8a610ed0d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['tok2vec', 'tagger', 'parser', 'attribute_ruler', 'lemmatizer', 'ner']"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "doc=nlp(\"Tesla Inc is going to acquire twitter for $45 billion\")\n",
        "for ent in doc.ents:\n",
        "  print(ent.text,\"|\",ent.label,\"|\",spacy.explain(ent.label_))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gSm671-_mtMO",
        "outputId": "c02da8a6-18da-49e7-cd2d-96e97bb81767"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tesla Inc | 383 | Companies, agencies, institutions, etc.\n",
            "$45 billion | 394 | Monetary values, including unit\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#List down all the entities"
      ],
      "metadata": {
        "id": "DR2eIZQert64"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Named entities supported by spacy\n",
        "\n",
        "nlp.pipe_labels['ner']"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YH1cfxZJn4Ou",
        "outputId": "ee42eb16-5d48-4af1-90be-b5983a35086a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['CARDINAL',\n",
              " 'DATE',\n",
              " 'EVENT',\n",
              " 'FAC',\n",
              " 'GPE',\n",
              " 'LANGUAGE',\n",
              " 'LAW',\n",
              " 'LOC',\n",
              " 'MONEY',\n",
              " 'NORP',\n",
              " 'ORDINAL',\n",
              " 'ORG',\n",
              " 'PERCENT',\n",
              " 'PERSON',\n",
              " 'PRODUCT',\n",
              " 'QUANTITY',\n",
              " 'TIME',\n",
              " 'WORK_OF_ART']"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "List of entities are also documented on this page: https://spacy.io/models/en"
      ],
      "metadata": {
        "id": "m6sqWezDr3dA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "doc = nlp(\"Michael Bloomberg founded Bloomberg Inc in 1982\")\n",
        "\n",
        "for ent in doc.ents:\n",
        "  print(ent.text,\"|\",ent.label_,\"|\",spacy.explain(ent.label_))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iXSvZKc9reMh",
        "outputId": "aed50454-7831-4f63-e650-c5556277890f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Michael Bloomberg | PERSON | People, including fictional\n",
            "Bloomberg Inc | ORG | Companies, agencies, institutions, etc.\n",
            "1982 | DATE | Absolute or relative dates or periods\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "s = doc[2:5]\n",
        "s"
      ],
      "metadata": {
        "id": "A6Eqq4unsBBq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "94d8709d-0e79-497f-f22b-d5e003c4df7c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "founded Bloomberg Inc"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Span Class"
      ],
      "metadata": {
        "id": "fmYHn5MleROo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from spacy.tokens import Span\n",
        "\n",
        "s1= Span(doc,0,1,label=\"ORG\")\n",
        "s2= Span(doc,5,6,label=\"ORG\")\n",
        "\n",
        "doc.set_ents([s1,s2],default=\"unmodified\")"
      ],
      "metadata": {
        "id": "R8mxaAScbrMl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for ent in doc.ents:\n",
        "  print(ent.text,\"|\",ent.label_)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MniLSzJde6vB",
        "outputId": "1b2a9eca-7fdf-45dd-a4b3-e8afc20e271e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Michael | ORG\n",
            "Bloomberg | PERSON\n",
            "Bloomberg Inc | ORG\n",
            "in | ORG\n",
            "1982 | DATE\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Excersie: 1\n",
        "Extract all the Geographical (cities, Countries, states) names from a given text"
      ],
      "metadata": {
        "id": "3GuYeqLEgHRa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "text = \"\"\"Kiran want to know the famous foods in each state of India. So, he opened Google and search for this question. Google showed that\n",
        "in Delhi it is Chaat, in Gujarat it is Dal Dhokli, in Tamilnadu it is Pongal, in Andhrapradesh it is Biryani, in Assam it is Papaya Khar,\n",
        "in Bihar it is Litti Chowkha and so on for all other states\"\"\"\n",
        "\n",
        "doc = nlp(text)\n",
        "\n",
        "\n",
        "\n",
        "#list for storing all the names\n",
        "all_gpe_names = []\n",
        "\n",
        "for ent in doc.ents:\n",
        "  if ent.label_ == 'GPE':     #checking the whether token belongs to entity \"GPE\" [Geographical location]\n",
        "    all_gpe_names.append(ent)\n",
        "\n",
        "\n",
        "\n",
        "#finally printing the results\n",
        "print(\"Geographical location Names: \", all_gpe_names)\n",
        "print(\"Count: \", len(all_gpe_names))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7p2nCb56fA4F",
        "outputId": "9a4d676c-aaaa-48da-9050-5ca0bee85ae1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Geographical location Names:  [India, Delhi, Gujarat, Tamilnadu, Pongal, Andhrapradesh, Assam, Bihar]\n",
            "Count:  8\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "w0M_mXEuhm41"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Excersie: 2\n",
        "Extract all the birth dates of cricketers in the given Text"
      ],
      "metadata": {
        "id": "_cMawbIkgYj6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "text = \"\"\"Sachin Tendulkar was born on 24 April 1973, Virat Kholi was born on 5 November 1988, Dhoni was born on 7 July 1981\n",
        "and finally Ricky ponting was born on 19 December 1974.\"\"\"\n",
        "\n",
        "doc = nlp(text)\n",
        "\n",
        "\n",
        "\n",
        "#list for storing all the dates\n",
        "all_birth_dates = []\n",
        "\n",
        "for ent in doc.ents:\n",
        "  if ent.label_ == 'DATE':     #checking the whether token belongs to entity \"DATE\" [Dates]\n",
        "    all_birth_dates.append(ent)\n",
        "\n",
        "\n",
        "\n",
        "#finally printing the results\n",
        "print(\"All Birth Dates: \", all_birth_dates)\n",
        "print(\"Count: \", len(all_birth_dates))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RNDRL-QvgSxs",
        "outputId": "d0409438-0c49-4976-cfa7-55e35659dbf2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "All Birth Dates:  [24 April 1973, 5 November 1988, 7 July 1981, 19 December 1974]\n",
            "Count:  4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "DyG7oL6wgx4Q"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}